{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T16:51:08.469793Z",
     "start_time": "2020-12-25T16:51:08.235740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max exercise tag : 123 Min exercise tag : 0\n",
      "len(train) : 3724 len(val) : 821 len(test) : 1215\n",
      "Train max_timeSteps : 200 Validation max_timeSteps : 200 Test max_timeSteps : 200\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "def load_data(path):\n",
    "    a = []\n",
    "    with open(path, 'r', encoding='utf-8') as f: \n",
    "        rdr = csv.reader(f)\n",
    "        for i in rdr:\n",
    "            i = list(map(int,i))\n",
    "            a.append(i)\n",
    "    return a\n",
    "def split_list(l, trunc_size=200):\n",
    "    if len(l)<=trunc_size:\n",
    "        return [l]\n",
    "    result = []\n",
    "    n = (len(l)-1)//trunc_size + 1\n",
    "    for i in range(n):\n",
    "        result.append(l[i*trunc_size:(i+1)*trunc_size])\n",
    "    return result\n",
    "def truncate(data):\n",
    "    #If len>200, split\n",
    "    result = []\n",
    "    for line in data:\n",
    "        for i in split_list(line):\n",
    "            result.append(i)\n",
    "            \n",
    "    return result\n",
    "train_q = load_data(\"./dataset/train_q.csv\")\n",
    "train_a = load_data(\"./dataset/train_a.csv\")\n",
    "test_q = load_data(\"./dataset/test_q.csv\")\n",
    "test_a = load_data(\"./dataset/test_a.csv\")\n",
    "\n",
    "train_q = truncate(train_q)\n",
    "train_a = truncate(train_a)\n",
    "test_q = truncate(test_q)\n",
    "test_a = truncate(test_a)\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_list(q,a, tolist=True):\n",
    "    tmp = list(zip(q,a))\n",
    "    random.shuffle(tmp)\n",
    "    q,a = zip(*tmp)\n",
    "    if tolist==False:\n",
    "        return [np.array(q), np.array(a)]\n",
    "    return [list(q),list(a)]\n",
    "\n",
    "train_q, train_a = shuffle_list(train_q, train_a)\n",
    "test_q, test_a = shuffle_list(test_q, test_a)\n",
    "\n",
    "print(\"Max exercise tag :\",max(map(max,train_q)), \"Min exercise tag :\",min(map(min,train_q)))\n",
    "val_q = train_q[3800:]\n",
    "val_a = train_a[3800:]\n",
    "train_q = train_q[:3800]\n",
    "train_a = train_a[:3800]\n",
    "train_q.sort(key=len)\n",
    "train_a.sort(key=len)\n",
    "val_q.sort(key=len)\n",
    "val_a.sort(key=len)\n",
    "test_q.sort(key=len)\n",
    "test_a.sort(key=len)\n",
    "\n",
    "def more_than_two(l):\n",
    "    for idx in range(len(l)):\n",
    "        if len(l[idx])>=2:\n",
    "            break\n",
    "    return l[idx:]\n",
    "train_q = more_than_two(train_q)\n",
    "train_a = more_than_two(train_a)\n",
    "val_q = more_than_two(val_q)\n",
    "val_a = more_than_two(val_a)\n",
    "test_q = more_than_two(test_q)\n",
    "test_a = more_than_two(test_a)\n",
    "\n",
    "print(\"len(train) :\", len(train_q), \"len(val) :\", len(val_q), \"len(test) :\", len(test_q))\n",
    "print(\"Train max_timeSteps :\", max([len(i) for i in train_q]), \n",
    "      \"Validation max_timeSteps :\", max([len(i) for i in val_q]), \n",
    "      \"Test max_timeSteps :\", max([len(i) for i in test_q]), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:04:07.189279Z",
     "start_time": "2020-12-25T19:04:07.169275Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tag_num = 125#124 + 1(zero padding)\n",
    "N = tag_num*2#number of tags x 2\n",
    "padding_value = -1\n",
    "batch_size = 256\n",
    "hidden_size = 200\n",
    "dropout_rate=0.4\n",
    "def make_batch(data):\n",
    "    #Dividing, zero padding\n",
    "    #Exercise tag : 1~124\n",
    "    #Answer = 1 | 2\n",
    "    result = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        padded_batch = keras.preprocessing.sequence.pad_sequences(batch, \n",
    "                                                                  padding=\"post\", value=padding_value)\n",
    "        result.append(padded_batch+1)\n",
    "    return result\n",
    "\n",
    "def encoding(q,a):\n",
    "    \n",
    "\n",
    "    encoding = np.eye(tag_num)\n",
    "    x=encoding[q]\n",
    "    x = np.concatenate((x,x*np.expand_dims(a//2, axis=-1)), axis=-1)\n",
    "        \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:04:07.698628Z",
     "start_time": "2020-12-25T19:04:07.591604Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Model, self).__init__(**kwargs)\n",
    "        self.embedding = layers.Embedding(input_dim=N, output_dim=N, mask_zero=True)\n",
    "        self.lstm = layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.dense = layers.Dense(tag_num, activation='sigmoid')\n",
    "        \n",
    "    def call(self, q,a, training=False):\n",
    "        inputs = encoding(q,a)\n",
    "        mask = self.embedding.compute_mask(q)\n",
    "        output = self.lstm(inputs, mask=mask, training=training)\n",
    "        output = self.dropout(output, training=training)\n",
    "        output = self.dense(output,training=training)\n",
    "        \n",
    "        return output\n",
    "def loss_acc(y,q,a):\n",
    "    en = encoding(q,a)\n",
    "    q = en[:,:,:tag_num]\n",
    "    a = en[:,:,tag_num:]\n",
    "    #y.shape = q.shape = a.shape = [batch_size, timesteps, tag_num]\n",
    "    #Loss = binary_cross_entropy(yT * qT+1, aT+1)\n",
    "    y_cropped = y[:, :-1, :]#y1...yT-1\n",
    "    q_cropped = q[:, 1:, :]#q2...qT\n",
    "    a_cropped = a[:, 1:, :]#a2...aT\n",
    "    \n",
    "    acc1 = y_cropped*q_cropped>0.5\n",
    "    acc2 = a_cropped\n",
    "    y_summed = tf.cast(tf.reduce_sum(y_cropped*q_cropped, axis=-1), dtype=tf.double)\n",
    "    a_summed = tf.cast(tf.reduce_sum(a_cropped, axis=-1), dtype=tf.double)\n",
    "    l=-a_summed * tf.math.log(y_summed+1e-07)-(1-a_summed)*tf.math.log(1-y_summed+1e-07)\n",
    "  \n",
    "    threshold = 0.5\n",
    "    \n",
    "    \n",
    "    m = tf.keras.metrics.AUC()\n",
    "    m.update_state(y_summed>threshold, a_summed)\n",
    "    auc = m.result()\n",
    "    #print(acc1[0])\n",
    "    return (tf.reduce_mean(l), auc)\n",
    "\n",
    "layer = Model()\n",
    "train_q_batches = make_batch(train_q)\n",
    "train_a_batches = make_batch(train_a)\n",
    "val_q_batches = make_batch(val_q)\n",
    "val_a_batches = make_batch(val_a)\n",
    "test_q_batches = make_batch(test_q)\n",
    "test_a_batches = make_batch(test_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:15:20.513940Z",
     "start_time": "2020-12-25T19:04:08.538294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_58 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch : 0 Train      loss : 0.6860496099776627 AUC : 0.5927751421928406\n",
      "Validation     loss : 0.6733153321329266 AUC : 0.6592308133840561\n",
      "Epoch : 1 Train      loss : 0.6727924116676225 AUC : 0.6333408832550049\n",
      "Validation     loss : 0.6482345534871163 AUC : 0.696875125169754\n",
      "Epoch : 2 Train      loss : 0.6559114420858172 AUC : 0.6607084830602011\n",
      "Validation     loss : 0.62243802864845 AUC : 0.7079610377550125\n",
      "Epoch : 3 Train      loss : 0.6390820559336796 AUC : 0.6793463349342347\n",
      "Validation     loss : 0.597958217863114 AUC : 0.7143687009811401\n",
      "Epoch : 4 Train      loss : 0.6234737418238858 AUC : 0.6862348755200702\n",
      "Validation     loss : 0.5745508862380915 AUC : 0.7151314914226532\n",
      "Epoch : 5 Train      loss : 0.6090455600090742 AUC : 0.6908247510592143\n",
      "Validation     loss : 0.5542418630019318 AUC : 0.7169571816921234\n",
      "Epoch : 6 Train      loss : 0.5968904280272214 AUC : 0.6976107279459635\n",
      "Validation     loss : 0.5354149105859889 AUC : 0.7182200849056244\n",
      "Epoch : 7 Train      loss : 0.5860156919334173 AUC : 0.6989471157391867\n",
      "Validation     loss : 0.5191329980155995 AUC : 0.7206707149744034\n",
      "Epoch : 8 Train      loss : 0.5763352137570299 AUC : 0.7027276158332824\n",
      "Validation     loss : 0.5055240864682052 AUC : 0.7209091335535049\n",
      "Epoch : 9 Train      loss : 0.5684381177958895 AUC : 0.7054139375686646\n",
      "Validation     loss : 0.4931838396771847 AUC : 0.7220501005649567\n",
      "Epoch : 10 Train      loss : 0.5610332340347342 AUC : 0.7091888864835103\n",
      "Validation     loss : 0.4829627798949757 AUC : 0.7234358638525009\n",
      "Epoch : 11 Train      loss : 0.5550401146705306 AUC : 0.7118518710136413\n",
      "Validation     loss : 0.47412763649166423 AUC : 0.7255280464887619\n",
      "Epoch : 12 Train      loss : 0.5494685485050126 AUC : 0.7130083521207174\n",
      "Validation     loss : 0.46677995289325136 AUC : 0.7284058928489685\n",
      "Epoch : 13 Train      loss : 0.5450821030419218 AUC : 0.7175756136576334\n",
      "Validation     loss : 0.46013736191495896 AUC : 0.7337044328451157\n",
      "Epoch : 14 Train      loss : 0.5410807311247163 AUC : 0.7198536356290182\n",
      "Validation     loss : 0.4543009214745842 AUC : 0.7363024353981018\n",
      "Epoch : 15 Train      loss : 0.5371179981373971 AUC : 0.721114699045817\n",
      "Validation     loss : 0.4490474069097793 AUC : 0.7370697855949402\n",
      "Epoch : 16 Train      loss : 0.5337443278312536 AUC : 0.7250099500020345\n",
      "Validation     loss : 0.44454645352335154 AUC : 0.7380337566137314\n",
      "Epoch : 17 Train      loss : 0.530540798989475 AUC : 0.7274273435274758\n",
      "Validation     loss : 0.4401958962159235 AUC : 0.7498470842838287\n",
      "Epoch : 18 Train      loss : 0.5272915391273238 AUC : 0.7310030023256938\n",
      "Validation     loss : 0.4365460321875756 AUC : 0.7509609460830688\n",
      "Epoch : 19 Train      loss : 0.5247137967248394 AUC : 0.7328157226244609\n",
      "Validation     loss : 0.43303345442088903 AUC : 0.7527711093425751\n",
      "Epoch : 20 Train      loss : 0.5221320615384384 AUC : 0.734253219763438\n",
      "Validation     loss : 0.42969564856613984 AUC : 0.7539872080087662\n",
      "Epoch : 21 Train      loss : 0.5194083841393715 AUC : 0.7369236469268798\n",
      "Validation     loss : 0.42661056667168706 AUC : 0.7545062303543091\n",
      "Epoch : 22 Train      loss : 0.5169458645059538 AUC : 0.7377442479133606\n",
      "Validation     loss : 0.42324435503007357 AUC : 0.755990207195282\n",
      "Epoch : 23 Train      loss : 0.5143222439287416 AUC : 0.7383574207623799\n",
      "Validation     loss : 0.42038936217674233 AUC : 0.7561872154474258\n",
      "Epoch : 24 Train      loss : 0.5117310700517517 AUC : 0.7404358307520549\n",
      "Validation     loss : 0.4177443013734138 AUC : 0.7557267993688583\n",
      "Epoch : 25 Train      loss : 0.5097567484845694 AUC : 0.7402108033498128\n",
      "Validation     loss : 0.4152481799528488 AUC : 0.7561169117689133\n",
      "Epoch : 26 Train      loss : 0.5072273340219524 AUC : 0.7427395900090535\n",
      "Validation     loss : 0.4127206816485469 AUC : 0.7563855350017548\n",
      "Epoch : 27 Train      loss : 0.5049885764720807 AUC : 0.7454800287882487\n",
      "Validation     loss : 0.41066736457930775 AUC : 0.7567615061998367\n",
      "Epoch : 28 Train      loss : 0.5030196070943922 AUC : 0.746596944332123\n",
      "Validation     loss : 0.40813984246159496 AUC : 0.7581235617399216\n",
      "Epoch : 29 Train      loss : 0.5006359085446962 AUC : 0.7497450788815816\n",
      "Validation     loss : 0.4061077812440079 AUC : 0.7603113949298859\n",
      "Epoch : 30 Train      loss : 0.4985090310665181 AUC : 0.751354734102885\n",
      "Validation     loss : 0.4037065223562668 AUC : 0.7597552835941315\n",
      "Epoch : 31 Train      loss : 0.4967017796391235 AUC : 0.7538859168688454\n",
      "Validation     loss : 0.40158319552925364 AUC : 0.7616149187088013\n",
      "Epoch : 32 Train      loss : 0.4942040372049598 AUC : 0.7547460357348124\n",
      "Validation     loss : 0.3991676073791862 AUC : 0.7695833891630173\n",
      "Epoch : 33 Train      loss : 0.49249002645640383 AUC : 0.7566619316736857\n",
      "Validation     loss : 0.3988531920413708 AUC : 0.7707316279411316\n",
      "Epoch : 34 Train      loss : 0.49082694250887204 AUC : 0.7570000847180685\n",
      "Validation     loss : 0.39584356151899225 AUC : 0.7713280916213989\n",
      "Epoch : 35 Train      loss : 0.48840178283253843 AUC : 0.7589942892392478\n",
      "Validation     loss : 0.3933221110281395 AUC : 0.7712840437889099\n",
      "Epoch : 36 Train      loss : 0.486362261673951 AUC : 0.7594617247581482\n",
      "Validation     loss : 0.3914741202858797 AUC : 0.7702929526567459\n",
      "Epoch : 37 Train      loss : 0.48459357311599316 AUC : 0.7608458797136942\n",
      "Validation     loss : 0.3898801174743307 AUC : 0.7714663296937943\n",
      "Epoch : 38 Train      loss : 0.4825869786297562 AUC : 0.7614407698313393\n",
      "Validation     loss : 0.3878935467198572 AUC : 0.7722526788711548\n",
      "Epoch : 39 Train      loss : 0.4810187331461939 AUC : 0.7613776048024494\n",
      "Validation     loss : 0.3886653438714448 AUC : 0.7708579003810883\n",
      "Epoch : 40 Train      loss : 0.48094507699231853 AUC : 0.7629014730453489\n",
      "Validation     loss : 0.3855711587043764 AUC : 0.7729120552539825\n",
      "Epoch : 41 Train      loss : 0.47906668887441417 AUC : 0.7640960733095806\n",
      "Validation     loss : 0.3844258955699988 AUC : 0.7774132639169693\n",
      "Epoch : 42 Train      loss : 0.47656083695576607 AUC : 0.7662723501523335\n",
      "Validation     loss : 0.382425644975377 AUC : 0.7714732736349106\n",
      "Epoch : 43 Train      loss : 0.4751468033884094 AUC : 0.7633655230204265\n",
      "Validation     loss : 0.38183174883521875 AUC : 0.7733335793018341\n",
      "Epoch : 44 Train      loss : 0.47472446627650045 AUC : 0.7660702109336853\n",
      "Validation     loss : 0.38236954937313505 AUC : 0.780129924416542\n",
      "Epoch : 45 Train      loss : 0.47469826454364417 AUC : 0.7662287950515746\n",
      "Validation     loss : 0.37964083766730977 AUC : 0.7781577855348587\n",
      "Epoch : 46 Train      loss : 0.4721267435654546 AUC : 0.7686510880788167\n",
      "Validation     loss : 0.37858179337707576 AUC : 0.7782720774412155\n",
      "Epoch : 47 Train      loss : 0.46995714137008393 AUC : 0.7690958619117737\n",
      "Validation     loss : 0.3766162603466061 AUC : 0.7802521288394928\n",
      "Epoch : 48 Train      loss : 0.46837433322823324 AUC : 0.7682239611943563\n",
      "Validation     loss : 0.37537535245970854 AUC : 0.78094781935215\n",
      "Epoch : 49 Train      loss : 0.4674493835972177 AUC : 0.7687414884567262\n",
      "Validation     loss : 0.3774897307452819 AUC : 0.785822868347168\n",
      "Epoch : 50 Train      loss : 0.4696633204618871 AUC : 0.7695672035217285\n",
      "Validation     loss : 0.3748821606519381 AUC : 0.7822252362966537\n",
      "Epoch : 51 Train      loss : 0.4664907698483356 AUC : 0.7695164243380228\n",
      "Validation     loss : 0.37353590458724995 AUC : 0.784617692232132\n",
      "Epoch : 52 Train      loss : 0.4649651434322239 AUC : 0.7737466613451639\n",
      "Validation     loss : 0.3723980944437417 AUC : 0.7876105159521103\n",
      "Epoch : 53 Train      loss : 0.46332633909610843 AUC : 0.7702997088432313\n",
      "Validation     loss : 0.3716486770627405 AUC : 0.7834231555461884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 54 Train      loss : 0.46293823457616107 AUC : 0.7709153970082601\n",
      "Validation     loss : 0.37025777416437755 AUC : 0.787147581577301\n",
      "Epoch : 55 Train      loss : 0.4621316971396654 AUC : 0.772428031762441\n",
      "Validation     loss : 0.36921604858882284 AUC : 0.7844553589820862\n",
      "Epoch : 56 Train      loss : 0.46111613038306537 AUC : 0.7724135915438334\n",
      "Validation     loss : 0.37361742996954295 AUC : 0.7751290798187256\n",
      "Epoch : 57 Train      loss : 0.46101634504534345 AUC : 0.7726358771324157\n",
      "Validation     loss : 0.3689377903025847 AUC : 0.78433957695961\n",
      "Epoch : 58 Train      loss : 0.45927930772857445 AUC : 0.7724591533342997\n",
      "Validation     loss : 0.3674445445149253 AUC : 0.7870320230722427\n",
      "Epoch : 59 Train      loss : 0.4590092603525777 AUC : 0.7744342207908631\n",
      "Validation     loss : 0.37025358237477146 AUC : 0.7800464928150177\n",
      "Epoch : 60 Train      loss : 0.4599259696577302 AUC : 0.7757877190907795\n",
      "Validation     loss : 0.36871202111642076 AUC : 0.7832355797290802\n",
      "Epoch : 61 Train      loss : 0.4582641299438409 AUC : 0.7721246282259624\n",
      "Validation     loss : 0.365754540496498 AUC : 0.7887151837348938\n",
      "Epoch : 62 Train      loss : 0.45714446889535054 AUC : 0.7769641637802124\n",
      "Validation     loss : 0.3653974499845556 AUC : 0.7875209003686905\n",
      "Epoch : 63 Train      loss : 0.45572822963516396 AUC : 0.7747673273086548\n",
      "Validation     loss : 0.3647679682585639 AUC : 0.7898451238870621\n",
      "Epoch : 64 Train      loss : 0.4560600801392035 AUC : 0.7727952520052592\n",
      "Validation     loss : 0.3642407134328487 AUC : 0.7924747616052628\n",
      "Epoch : 65 Train      loss : 0.45494407723603325 AUC : 0.7775598247845968\n",
      "Validation     loss : 0.36493489661070866 AUC : 0.7840281426906586\n",
      "Epoch : 66 Train      loss : 0.45402439731642974 AUC : 0.7740692774454754\n",
      "Validation     loss : 0.3626070349458421 AUC : 0.7900523692369461\n",
      "Epoch : 67 Train      loss : 0.4532210381528339 AUC : 0.7751593708992004\n",
      "Validation     loss : 0.36229670210915715 AUC : 0.7910706251859665\n",
      "Epoch : 68 Train      loss : 0.4527646493960155 AUC : 0.773735519250234\n",
      "Validation     loss : 0.36199386184878457 AUC : 0.7944740355014801\n",
      "Epoch : 69 Train      loss : 0.4519860816652372 AUC : 0.7773344318072002\n",
      "Validation     loss : 0.36691325072371295 AUC : 0.7779992818832397\n",
      "Epoch : 70 Train      loss : 0.4522580604104755 AUC : 0.7768268624941508\n",
      "Validation     loss : 0.3668610906292386 AUC : 0.7995657622814178\n",
      "Epoch : 71 Train      loss : 0.45295272803922676 AUC : 0.7772529323895774\n",
      "Validation     loss : 0.36118034871069277 AUC : 0.788773313164711\n",
      "Epoch : 72 Train      loss : 0.45126561751425276 AUC : 0.7774086117744446\n",
      "Validation     loss : 0.3615575823470953 AUC : 0.7894820719957352\n",
      "Epoch : 73 Train      loss : 0.4504386870059411 AUC : 0.7759571154912313\n",
      "Validation     loss : 0.35999062515047736 AUC : 0.7918500751256943\n",
      "Epoch : 74 Train      loss : 0.44954152071251385 AUC : 0.7773489952087402\n",
      "Validation     loss : 0.3590493044834515 AUC : 0.7959323078393936\n",
      "Epoch : 75 Train      loss : 0.44865005414271025 AUC : 0.7788431723912557\n",
      "Validation     loss : 0.3610646684314998 AUC : 0.7843652665615082\n",
      "Epoch : 76 Train      loss : 0.45016852290846815 AUC : 0.7792506615320842\n",
      "Validation     loss : 0.3609343776716818 AUC : 0.7876662760972977\n",
      "Epoch : 77 Train      loss : 0.45037675791529297 AUC : 0.7774823784828188\n",
      "Validation     loss : 0.3595352270738522 AUC : 0.791924238204956\n",
      "Epoch : 78 Train      loss : 0.4483737291813506 AUC : 0.7785279472668966\n",
      "Validation     loss : 0.35904892937100985 AUC : 0.7964760065078735\n",
      "Epoch : 79 Train      loss : 0.44768255026223736 AUC : 0.7789491335550944\n",
      "Validation     loss : 0.3577408392778668 AUC : 0.791819304227829\n",
      "Epoch : 80 Train      loss : 0.4465943464647194 AUC : 0.7784208655357362\n",
      "Validation     loss : 0.3578427683633718 AUC : 0.7997143268585205\n",
      "Epoch : 81 Train      loss : 0.44668998552862904 AUC : 0.7798406004905701\n",
      "Validation     loss : 0.35784056498499445 AUC : 0.7897560000419617\n",
      "Epoch : 82 Train      loss : 0.44575652552608436 AUC : 0.779190436999003\n",
      "Validation     loss : 0.35687698374410753 AUC : 0.7981898784637451\n",
      "Epoch : 83 Train      loss : 0.44530962260118245 AUC : 0.7787973523139954\n",
      "Validation     loss : 0.35692280116946545 AUC : 0.791036918759346\n",
      "Epoch : 84 Train      loss : 0.44555641193585543 AUC : 0.7823183417320252\n",
      "Validation     loss : 0.35666486712881323 AUC : 0.7939763069152832\n",
      "Epoch : 85 Train      loss : 0.44644547632360476 AUC : 0.779089872042338\n",
      "Validation     loss : 0.35697233399809297 AUC : 0.7939946353435516\n",
      "Epoch : 86 Train      loss : 0.44565359707922997 AUC : 0.780909017721812\n",
      "Validation     loss : 0.35711595172614236 AUC : 0.7894852608442307\n",
      "Epoch : 87 Train      loss : 0.4457810334373196 AUC : 0.7781957030296327\n",
      "Validation     loss : 0.3562624651334683 AUC : 0.7938028424978256\n",
      "Epoch : 88 Train      loss : 0.44547805350248587 AUC : 0.7801950852076214\n",
      "Validation     loss : 0.3559964504330904 AUC : 0.8016466945409775\n",
      "---------------------saved--------------------\n",
      "Epoch : 89 Train      loss : 0.44448097545770227 AUC : 0.7825916330019634\n",
      "Validation     loss : 0.354886963811357 AUC : 0.7942869663238525\n",
      "Epoch : 90 Train      loss : 0.4435271708045282 AUC : 0.779004466533661\n",
      "Validation     loss : 0.3548920874172767 AUC : 0.7969656884670258\n",
      "Epoch : 91 Train      loss : 0.4422811174582043 AUC : 0.7816927115122477\n",
      "Validation     loss : 0.35426375372633123 AUC : 0.7949478775262833\n",
      "Epoch : 92 Train      loss : 0.44158234116485706 AUC : 0.7819273829460145\n",
      "Validation     loss : 0.3535760437067731 AUC : 0.7973006665706635\n",
      "Epoch : 93 Train      loss : 0.44170265434818706 AUC : 0.7807140906651814\n",
      "Validation     loss : 0.3533705066245588 AUC : 0.7961482405662537\n",
      "Epoch : 94 Train      loss : 0.44086563552827557 AUC : 0.7820635398228964\n",
      "Validation     loss : 0.3558126951331845 AUC : 0.7863361239433289\n",
      "Epoch : 95 Train      loss : 0.441306712071013 AUC : 0.7816694895426433\n",
      "Validation     loss : 0.3538230761296375 AUC : 0.79915651679039\n",
      "Epoch : 96 Train      loss : 0.4410640614575065 AUC : 0.7823265910148622\n",
      "Validation     loss : 0.35254394509782 AUC : 0.7982596606016159\n",
      "Epoch : 97 Train      loss : 0.4403139231489544 AUC : 0.781783358256022\n",
      "Validation     loss : 0.3529959173611446 AUC : 0.7986270487308502\n",
      "Epoch : 98 Train      loss : 0.44046849793100146 AUC : 0.782516360282898\n",
      "Validation     loss : 0.3531657044207055 AUC : 0.7991321980953217\n",
      "Epoch : 99 Train      loss : 0.4394083654260254 AUC : 0.7821139891942341\n",
      "Validation     loss : 0.35369545639749445 AUC : 0.8045754581689835\n",
      "---------------------saved--------------------\n",
      "Epoch : 100 Train      loss : 0.44166798000300145 AUC : 0.7819724043210348\n",
      "Validation     loss : 0.3540062613307665 AUC : 0.792623296380043\n",
      "Epoch : 101 Train      loss : 0.4400092920703446 AUC : 0.7818291902542115\n",
      "Validation     loss : 0.3536999412991926 AUC : 0.8006888180971146\n",
      "Epoch : 102 Train      loss : 0.4393570281001578 AUC : 0.7837323745091757\n",
      "Validation     loss : 0.3520002889497233 AUC : 0.7945673316717148\n",
      "Epoch : 103 Train      loss : 0.43863778796275665 AUC : 0.7842162251472473\n",
      "Validation     loss : 0.35288268551568264 AUC : 0.7916628122329712\n",
      "Epoch : 104 Train      loss : 0.439365962793771 AUC : 0.7824263334274293\n",
      "Validation     loss : 0.35344743737328105 AUC : 0.8049897104501724\n",
      "---------------------saved--------------------\n",
      "Epoch : 105 Train      loss : 0.4392211090783058 AUC : 0.7833166917165121\n",
      "Validation     loss : 0.35487717258484264 AUC : 0.7864812165498734\n",
      "Epoch : 106 Train      loss : 0.4405476589308519 AUC : 0.7812640070915222\n",
      "Validation     loss : 0.35362445870601733 AUC : 0.7913922071456909\n",
      "Epoch : 107 Train      loss : 0.4382893003074985 AUC : 0.7825406153996785\n",
      "Validation     loss : 0.3510187489741193 AUC : 0.7969208210706711\n",
      "Epoch : 108 Train      loss : 0.4371015257404139 AUC : 0.783810273806254\n",
      "Validation     loss : 0.3507555126742869 AUC : 0.7944888919591904\n",
      "Epoch : 109 Train      loss : 0.43725329587759154 AUC : 0.783338228861491\n",
      "Validation     loss : 0.35116182070348967 AUC : 0.8023651987314224\n",
      "Epoch : 110 Train      loss : 0.4368409936187831 AUC : 0.7842747171719868\n",
      "Validation     loss : 0.3503246572132593 AUC : 0.7949857115745544\n",
      "Epoch : 111 Train      loss : 0.4370460917152365 AUC : 0.7828778266906737\n",
      "Validation     loss : 0.3505969532635905 AUC : 0.8001079559326172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 112 Train      loss : 0.4363680997727907 AUC : 0.7836678504943848\n",
      "Validation     loss : 0.3499713946263666 AUC : 0.7975707799196243\n",
      "Epoch : 113 Train      loss : 0.43534412463558136 AUC : 0.7844645102818806\n",
      "Validation     loss : 0.3497120653775629 AUC : 0.8006014078855515\n",
      "Epoch : 114 Train      loss : 0.4353859698952097 AUC : 0.7847859700520833\n",
      "Validation     loss : 0.349592559834518 AUC : 0.7991063147783279\n",
      "Epoch : 115 Train      loss : 0.4350266529452866 AUC : 0.7843913555145262\n",
      "Validation     loss : 0.3493861989641556 AUC : 0.8001220375299454\n",
      "Epoch : 116 Train      loss : 0.4346851309189509 AUC : 0.7841803312301636\n",
      "Validation     loss : 0.3493130446058662 AUC : 0.799480751156807\n",
      "Epoch : 117 Train      loss : 0.4345627505439845 AUC : 0.7841788649559023\n",
      "Validation     loss : 0.3495707632995644 AUC : 0.7970443665981293\n",
      "Epoch : 118 Train      loss : 0.43491342723998844 AUC : 0.7852106968561807\n",
      "Validation     loss : 0.35054039107274215 AUC : 0.7918578833341599\n",
      "Epoch : 119 Train      loss : 0.43991792760990167 AUC : 0.7813113689422606\n",
      "Validation     loss : 0.3535893140444677 AUC : 0.7898963093757629\n",
      "Epoch : 120 Train      loss : 0.437108875860097 AUC : 0.7854764183362325\n",
      "Validation     loss : 0.3515651569978081 AUC : 0.7897010892629623\n",
      "Epoch : 121 Train      loss : 0.43506255338766553 AUC : 0.7835697929064432\n",
      "Validation     loss : 0.3497391159436423 AUC : 0.7986321449279785\n",
      "Epoch : 122 Train      loss : 0.4347037077111439 AUC : 0.7857098778088887\n",
      "Validation     loss : 0.34839190240975876 AUC : 0.7960449010133743\n",
      "Epoch : 123 Train      loss : 0.4337340544673768 AUC : 0.7841727018356324\n",
      "Validation     loss : 0.3486196033499795 AUC : 0.800072968006134\n",
      "Epoch : 124 Train      loss : 0.4330196976451117 AUC : 0.7852440595626833\n",
      "Validation     loss : 0.34825078640336976 AUC : 0.7957788109779358\n",
      "Epoch : 125 Train      loss : 0.4340533394958434 AUC : 0.7855208118756611\n",
      "Validation     loss : 0.3484833832033683 AUC : 0.7968740463256836\n",
      "Epoch : 126 Train      loss : 0.43366340853503393 AUC : 0.7822711785634359\n",
      "Validation     loss : 0.34956101063168404 AUC : 0.7992167770862579\n",
      "Epoch : 127 Train      loss : 0.43405034660696007 AUC : 0.7864701231320699\n",
      "Validation     loss : 0.3495186612742078 AUC : 0.7924718856811523\n",
      "Epoch : 128 Train      loss : 0.4337549569872854 AUC : 0.7834451158841452\n",
      "Validation     loss : 0.34842879224533 AUC : 0.8023291081190109\n",
      "Epoch : 129 Train      loss : 0.43247170305215354 AUC : 0.7870648145675658\n",
      "Validation     loss : 0.3485330846009569 AUC : 0.7941799163818359\n",
      "Epoch : 130 Train      loss : 0.4323617614616274 AUC : 0.783813468615214\n",
      "Validation     loss : 0.34777892621067147 AUC : 0.8046631515026093\n",
      "Epoch : 131 Train      loss : 0.43285664416772784 AUC : 0.7858727216720582\n",
      "Validation     loss : 0.3489324471915425 AUC : 0.794132649898529\n",
      "Epoch : 132 Train      loss : 0.43445132190652885 AUC : 0.7852044860521952\n",
      "Validation     loss : 0.35220159645309396 AUC : 0.8030694872140884\n",
      "Epoch : 133 Train      loss : 0.4344714277134758 AUC : 0.7866035064061484\n",
      "Validation     loss : 0.3474763035579479 AUC : 0.7986335754394531\n",
      "Epoch : 134 Train      loss : 0.43177483449880355 AUC : 0.7853889385859172\n",
      "Validation     loss : 0.3472571895867034 AUC : 0.7964640259742737\n",
      "Epoch : 135 Train      loss : 0.43172410177880016 AUC : 0.7851413528124491\n",
      "Validation     loss : 0.34699035626791963 AUC : 0.800325483083725\n",
      "Epoch : 136 Train      loss : 0.4305845446236833 AUC : 0.7866664250691732\n",
      "Validation     loss : 0.34707918553743006 AUC : 0.8010009825229645\n",
      "Epoch : 137 Train      loss : 0.43059951842349853 AUC : 0.7865779399871826\n",
      "Validation     loss : 0.3472514690954622 AUC : 0.8030463755130768\n",
      "Epoch : 138 Train      loss : 0.43136114122933367 AUC : 0.7859237591425579\n",
      "Validation     loss : 0.34782004129499416 AUC : 0.7934727817773819\n",
      "Epoch : 139 Train      loss : 0.43081331213722956 AUC : 0.7874220808347067\n",
      "Validation     loss : 0.3465450489431138 AUC : 0.805291473865509\n",
      "---------------------saved--------------------\n",
      "Epoch : 140 Train      loss : 0.43053365589129095 AUC : 0.7872525254885356\n",
      "Validation     loss : 0.34712618775193693 AUC : 0.7968337088823318\n",
      "Epoch : 141 Train      loss : 0.43011552273326076 AUC : 0.7871360262235007\n",
      "Validation     loss : 0.3468636480465754 AUC : 0.8042683899402618\n",
      "Epoch : 142 Train      loss : 0.4297413618143143 AUC : 0.7876195391019183\n",
      "Validation     loss : 0.3467405577833962 AUC : 0.8027202636003494\n",
      "Epoch : 143 Train      loss : 0.4295387137335985 AUC : 0.7866260766983032\n",
      "Validation     loss : 0.3462788429698089 AUC : 0.7951148748397827\n",
      "Epoch : 144 Train      loss : 0.4313360088545847 AUC : 0.784645728270213\n",
      "Validation     loss : 0.34913703475599495 AUC : 0.79535211622715\n",
      "Epoch : 145 Train      loss : 0.4320728534391453 AUC : 0.7874109625816346\n",
      "Validation     loss : 0.347459247459468 AUC : 0.8039292246103287\n",
      "Epoch : 146 Train      loss : 0.42977915036628583 AUC : 0.7873246391614278\n",
      "Validation     loss : 0.3459796230663533 AUC : 0.8010074943304062\n",
      "Epoch : 147 Train      loss : 0.4288253282661682 AUC : 0.7874511361122131\n",
      "Validation     loss : 0.34564666414095946 AUC : 0.798581913113594\n",
      "Epoch : 148 Train      loss : 0.4288075842405805 AUC : 0.7881829380989074\n",
      "Validation     loss : 0.34566274407004904 AUC : 0.8005684018135071\n",
      "Epoch : 149 Train      loss : 0.42785491227636185 AUC : 0.7876272479693096\n",
      "Validation     loss : 0.3457877466098128 AUC : 0.7997625321149826\n",
      "Epoch : 150 Train      loss : 0.42842244594202544 AUC : 0.7881193637847901\n",
      "Validation     loss : 0.3450594349185894 AUC : 0.8002252131700516\n",
      "Epoch : 151 Train      loss : 0.43098209512615615 AUC : 0.7868112007776896\n",
      "Validation     loss : 0.3469264911549911 AUC : 0.7967322319746017\n",
      "Epoch : 152 Train      loss : 0.4301519199456372 AUC : 0.7862027883529662\n",
      "Validation     loss : 0.3460872152348089 AUC : 0.8058685213327408\n",
      "---------------------saved--------------------\n",
      "Epoch : 153 Train      loss : 0.4295424789787261 AUC : 0.7892002224922181\n",
      "Validation     loss : 0.3452579704747849 AUC : 0.8009426444768906\n",
      "Epoch : 154 Train      loss : 0.42799657671495767 AUC : 0.7866551876068115\n",
      "Validation     loss : 0.3449969304338476 AUC : 0.7959668785333633\n",
      "Epoch : 155 Train      loss : 0.427914509787421 AUC : 0.7876782377560932\n",
      "Validation     loss : 0.3446302665820352 AUC : 0.8008435815572739\n",
      "Epoch : 156 Train      loss : 0.42743120515938965 AUC : 0.786868969599406\n",
      "Validation     loss : 0.34450668156962416 AUC : 0.8022326529026031\n",
      "Epoch : 157 Train      loss : 0.42805850467033 AUC : 0.7892076214154562\n",
      "Validation     loss : 0.3463464363703172 AUC : 0.7930669039487839\n",
      "Epoch : 158 Train      loss : 0.4289093422799423 AUC : 0.7857436617215473\n",
      "Validation     loss : 0.3455661227741223 AUC : 0.8070482015609741\n",
      "---------------------saved--------------------\n",
      "Epoch : 159 Train      loss : 0.4299089120279431 AUC : 0.7897255142529807\n",
      "Validation     loss : 0.3448848804884229 AUC : 0.8007682412862778\n",
      "Epoch : 160 Train      loss : 0.4277704095691104 AUC : 0.7866318742434183\n",
      "Validation     loss : 0.34488963987661736 AUC : 0.7986055910587311\n",
      "Epoch : 161 Train      loss : 0.4265476737827066 AUC : 0.7878653446833294\n",
      "Validation     loss : 0.34407903142542007 AUC : 0.801909476518631\n",
      "Epoch : 162 Train      loss : 0.42615536833769746 AUC : 0.7884029428164163\n",
      "Validation     loss : 0.34410497134864254 AUC : 0.8013734519481659\n",
      "Epoch : 163 Train      loss : 0.42611415926573504 AUC : 0.7879413406054179\n",
      "Validation     loss : 0.34446949475726857 AUC : 0.8026376813650131\n",
      "Epoch : 164 Train      loss : 0.426168369327556 AUC : 0.7881087144215901\n",
      "Validation     loss : 0.34475906147006585 AUC : 0.8012628257274628\n",
      "Epoch : 165 Train      loss : 0.4259281217145449 AUC : 0.7873666683832805\n",
      "Validation     loss : 0.34489556694381607 AUC : 0.8002786338329315\n",
      "Epoch : 166 Train      loss : 0.425671917661581 AUC : 0.7894439260164897\n",
      "Validation     loss : 0.3437768396198838 AUC : 0.8003989160060883\n",
      "Epoch : 167 Train      loss : 0.42566611767717244 AUC : 0.788496486345927\n",
      "Validation     loss : 0.34401868733036556 AUC : 0.8015829026699066\n",
      "Epoch : 168 Train      loss : 0.42599625949958286 AUC : 0.7889807860056559\n",
      "Validation     loss : 0.34534525345786604 AUC : 0.7952184975147247\n",
      "Epoch : 169 Train      loss : 0.4258968302678371 AUC : 0.7885570804278056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation     loss : 0.3446506592249058 AUC : 0.8018522709608078\n",
      "Epoch : 170 Train      loss : 0.4257755576313103 AUC : 0.7884593407313029\n",
      "Validation     loss : 0.34410911864991134 AUC : 0.8011561036109924\n",
      "Epoch : 171 Train      loss : 0.4254994878435883 AUC : 0.789274752140045\n",
      "Validation     loss : 0.3435985172791654 AUC : 0.8031279593706131\n",
      "Epoch : 172 Train      loss : 0.42472514334939954 AUC : 0.7886691093444824\n",
      "Validation     loss : 0.343423218880123 AUC : 0.8030894696712494\n",
      "Epoch : 173 Train      loss : 0.425193860226866 AUC : 0.7882925828297932\n",
      "Validation     loss : 0.3434330288955204 AUC : 0.8012236058712006\n",
      "Epoch : 174 Train      loss : 0.425370823555619 AUC : 0.7868999799092609\n",
      "Validation     loss : 0.3436916797681831 AUC : 0.8062853217124939\n",
      "Epoch : 175 Train      loss : 0.4266507156039046 AUC : 0.7878207365671793\n",
      "Validation     loss : 0.3452463790536958 AUC : 0.8041252940893173\n",
      "Epoch : 176 Train      loss : 0.4262038430684975 AUC : 0.7901382088661194\n",
      "Validation     loss : 0.3443208359385752 AUC : 0.797164186835289\n",
      "Epoch : 177 Train      loss : 0.4247504042991166 AUC : 0.7891392191251116\n",
      "Validation     loss : 0.34381747122715317 AUC : 0.8042169809341431\n",
      "Epoch : 178 Train      loss : 0.424217688672264 AUC : 0.7891788403193156\n",
      "Validation     loss : 0.3434099158351135 AUC : 0.8009091764688492\n",
      "Epoch : 179 Train      loss : 0.4256624109112983 AUC : 0.7871253768603007\n",
      "Validation     loss : 0.3442462598936828 AUC : 0.8043410927057266\n",
      "Epoch : 180 Train      loss : 0.4244242744819986 AUC : 0.7906645099322\n",
      "Validation     loss : 0.3440849656631763 AUC : 0.8014684170484543\n",
      "Epoch : 181 Train      loss : 0.4238645698139224 AUC : 0.7893669764200847\n",
      "Validation     loss : 0.34313486373556595 AUC : 0.7973021864891052\n",
      "Epoch : 182 Train      loss : 0.42369792636978143 AUC : 0.788764238357544\n",
      "Validation     loss : 0.34333498705088106 AUC : 0.8072682619094849\n",
      "---------------------saved--------------------\n",
      "Epoch : 183 Train      loss : 0.42433716110286884 AUC : 0.788759708404541\n",
      "Validation     loss : 0.3427666580133213 AUC : 0.8021467179059982\n",
      "Epoch : 184 Train      loss : 0.42344484580892594 AUC : 0.7908907492955526\n",
      "Validation     loss : 0.345311778118217 AUC : 0.8096351474523544\n",
      "---------------------saved--------------------\n",
      "Epoch : 185 Train      loss : 0.42565543387049504 AUC : 0.7892006953557331\n",
      "Validation     loss : 0.343756754331816 AUC : 0.7988806217908859\n",
      "Epoch : 186 Train      loss : 0.424949912292187 AUC : 0.7892171144485473\n",
      "Validation     loss : 0.3428222364792176 AUC : 0.8018624633550644\n",
      "Epoch : 187 Train      loss : 0.42399168681448623 AUC : 0.7889821648597718\n",
      "Validation     loss : 0.3430299236507235 AUC : 0.7993353754281998\n",
      "Epoch : 188 Train      loss : 0.4247390492857258 AUC : 0.7886353453000386\n",
      "Validation     loss : 0.3428676998627063 AUC : 0.8002047538757324\n",
      "Epoch : 189 Train      loss : 0.42495466349849903 AUC : 0.789466913541158\n",
      "Validation     loss : 0.34314223675004796 AUC : 0.8041170835494995\n",
      "Epoch : 190 Train      loss : 0.42378307437785057 AUC : 0.7898498574892681\n",
      "Validation     loss : 0.3422813891256591 AUC : 0.803586408495903\n",
      "Epoch : 191 Train      loss : 0.4235665706108863 AUC : 0.7898371299107871\n",
      "Validation     loss : 0.3422780602540344 AUC : 0.8007744997739792\n",
      "Epoch : 192 Train      loss : 0.42319620463672375 AUC : 0.7905735452969869\n",
      "Validation     loss : 0.3421923638020593 AUC : 0.8047308623790741\n",
      "Epoch : 193 Train      loss : 0.4228686871051126 AUC : 0.7886436700820924\n",
      "Validation     loss : 0.3426048233025187 AUC : 0.8039298504590988\n",
      "Epoch : 194 Train      loss : 0.42278394897690824 AUC : 0.7890459338823954\n",
      "Validation     loss : 0.34232965217965855 AUC : 0.8067366182804108\n",
      "Epoch : 195 Train      loss : 0.4219474594507529 AUC : 0.7916047573089601\n",
      "Validation     loss : 0.34212169334147885 AUC : 0.8017356246709824\n",
      "Epoch : 196 Train      loss : 0.4218329272323514 AUC : 0.7891014774640401\n",
      "Validation     loss : 0.34269379271876604 AUC : 0.8071495741605759\n",
      "Epoch : 197 Train      loss : 0.42188068984253124 AUC : 0.7914126157760619\n",
      "Validation     loss : 0.3424339030719531 AUC : 0.8012465387582779\n",
      "Epoch : 198 Train      loss : 0.4223277673354103 AUC : 0.7892998576164245\n",
      "Validation     loss : 0.3421996126589908 AUC : 0.8073620796203613\n",
      "Epoch : 199 Train      loss : 0.42250847439887806 AUC : 0.788511327902476\n",
      "Validation     loss : 0.34242438809341846 AUC : 0.8032399117946625\n",
      "Epoch : 200 Train      loss : 0.4220622212050059 AUC : 0.7905742645263671\n",
      "Validation     loss : 0.34214061043114763 AUC : 0.8026972115039825\n",
      "Epoch : 201 Train      loss : 0.42147851409879833 AUC : 0.7904658913612365\n",
      "Validation     loss : 0.34223410212119143 AUC : 0.8035766333341599\n",
      "Epoch : 202 Train      loss : 0.4214292226864643 AUC : 0.7905142426490784\n",
      "Validation     loss : 0.34297030924323035 AUC : 0.8059929758310318\n",
      "Epoch : 203 Train      loss : 0.42097022869161826 AUC : 0.7908596436182659\n",
      "Validation     loss : 0.34196803675019755 AUC : 0.8057202249765396\n",
      "Epoch : 204 Train      loss : 0.4209262773242093 AUC : 0.7905031561851502\n",
      "Validation     loss : 0.34287216343021576 AUC : 0.7973349392414093\n",
      "Epoch : 205 Train      loss : 0.42137532865253324 AUC : 0.7923105796178183\n",
      "Validation     loss : 0.34231114263304036 AUC : 0.8033942133188248\n",
      "Epoch : 206 Train      loss : 0.42115286707543603 AUC : 0.7902591943740844\n",
      "Validation     loss : 0.3428330227406518 AUC : 0.8078269958496094\n",
      "Epoch : 207 Train      loss : 0.42130578150257936 AUC : 0.7901636600494385\n",
      "Validation     loss : 0.34159037426393946 AUC : 0.8017310500144958\n",
      "Epoch : 208 Train      loss : 0.4219798094231666 AUC : 0.791716702779134\n",
      "Validation     loss : 0.34192810108851435 AUC : 0.8071947246789932\n",
      "Epoch : 209 Train      loss : 0.4210663339765151 AUC : 0.7900490442911784\n",
      "Validation     loss : 0.342172240617228 AUC : 0.8062234222888947\n",
      "Epoch : 210 Train      loss : 0.4206686432849366 AUC : 0.7909090638160705\n",
      "Validation     loss : 0.3425232407975117 AUC : 0.8026602417230606\n",
      "Epoch : 211 Train      loss : 0.4208093305076207 AUC : 0.7916354894638062\n",
      "Validation     loss : 0.34198718720050286 AUC : 0.8029621690511703\n",
      "Epoch : 212 Train      loss : 0.420124931203948 AUC : 0.7905534505844115\n",
      "Validation     loss : 0.3418368902638604 AUC : 0.8098156601190567\n",
      "---------------------saved--------------------\n",
      "Epoch : 213 Train      loss : 0.42070466367660236 AUC : 0.7915234367052714\n",
      "Validation     loss : 0.34143693966566746 AUC : 0.8042144924402237\n",
      "Epoch : 214 Train      loss : 0.4210853941481461 AUC : 0.7918886144955954\n",
      "Validation     loss : 0.34238500327784416 AUC : 0.7988019436597824\n",
      "Epoch : 215 Train      loss : 0.42331645334282497 AUC : 0.7886245528856912\n",
      "Validation     loss : 0.3423311251568388 AUC : 0.8015983253717422\n",
      "Epoch : 216 Train      loss : 0.421558121121728 AUC : 0.7907421628634136\n",
      "Validation     loss : 0.34141111116846756 AUC : 0.8024652451276779\n",
      "Epoch : 217 Train      loss : 0.420533168219345 AUC : 0.7916439612706504\n",
      "Validation     loss : 0.3412136875334111 AUC : 0.7999582588672638\n",
      "Epoch : 218 Train      loss : 0.4197659060313512 AUC : 0.7914188663164776\n",
      "Validation     loss : 0.342082263848366 AUC : 0.8010291457176208\n",
      "Epoch : 219 Train      loss : 0.4192223950581003 AUC : 0.7914744416872661\n",
      "Validation     loss : 0.34181322573157497 AUC : 0.8063244521617889\n",
      "Epoch : 220 Train      loss : 0.41947508053512106 AUC : 0.7918690959612529\n",
      "Validation     loss : 0.3421203041340201 AUC : 0.8024338483810425\n",
      "Epoch : 221 Train      loss : 0.41969524330110575 AUC : 0.7920016606648764\n",
      "Validation     loss : 0.3421380649202712 AUC : 0.8017912358045578\n",
      "Epoch : 222 Train      loss : 0.41945415600124997 AUC : 0.7904053767522176\n",
      "Validation     loss : 0.3427941680375993 AUC : 0.7957894802093506\n",
      "Epoch : 223 Train      loss : 0.42070536457862384 AUC : 0.7921738783518472\n",
      "Validation     loss : 0.3417210045890893 AUC : 0.8049473166465759\n",
      "Epoch : 224 Train      loss : 0.4204334368910143 AUC : 0.7922948757807412\n",
      "Validation     loss : 0.3414351597748063 AUC : 0.8024964332580566\n",
      "Epoch : 225 Train      loss : 0.42081383877627154 AUC : 0.7910385211308798\n",
      "Validation     loss : 0.3409088077813893 AUC : 0.8026171624660492\n",
      "Epoch : 226 Train      loss : 0.4207540791139131 AUC : 0.7915830095609028\n",
      "Validation     loss : 0.3412041461763632 AUC : 0.8087586611509323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 227 Train      loss : 0.4192321927305064 AUC : 0.7923433939615885\n",
      "Validation     loss : 0.34095966401806593 AUC : 0.8020363599061966\n",
      "Epoch : 228 Train      loss : 0.4188229850531013 AUC : 0.7917260448137918\n",
      "Validation     loss : 0.34182596508788293 AUC : 0.8025823533535004\n",
      "Epoch : 229 Train      loss : 0.4187110755165977 AUC : 0.791830571492513\n",
      "Validation     loss : 0.3413208361065663 AUC : 0.8076839447021484\n",
      "Epoch : 230 Train      loss : 0.41894866705429096 AUC : 0.7917407472928365\n",
      "Validation     loss : 0.3410722321092914 AUC : 0.8066537827253342\n",
      "Epoch : 231 Train      loss : 0.4187973785444517 AUC : 0.7915300130844116\n",
      "Validation     loss : 0.34063585673783736 AUC : 0.8045081794261932\n",
      "Epoch : 232 Train      loss : 0.41832032375511524 AUC : 0.792275051275889\n",
      "Validation     loss : 0.3412312276141827 AUC : 0.8016869574785233\n",
      "Epoch : 233 Train      loss : 0.4179576933209997 AUC : 0.7931428750356039\n",
      "Validation     loss : 0.3403711711572006 AUC : 0.8063953816890717\n",
      "Epoch : 234 Train      loss : 0.4185477721845673 AUC : 0.7920606136322023\n",
      "Validation     loss : 0.34134318279336373 AUC : 0.8034664243459702\n",
      "Epoch : 235 Train      loss : 0.4184434146740681 AUC : 0.7915056427319844\n",
      "Validation     loss : 0.340394692936245 AUC : 0.8050264567136765\n",
      "Epoch : 236 Train      loss : 0.4182201768147955 AUC : 0.7918384194374085\n",
      "Validation     loss : 0.340907853362995 AUC : 0.8005801141262054\n",
      "Epoch : 237 Train      loss : 0.41829349583688197 AUC : 0.7929140369097393\n",
      "Validation     loss : 0.34044914443398494 AUC : 0.8036072850227356\n",
      "Epoch : 238 Train      loss : 0.417641957245136 AUC : 0.792264993985494\n",
      "Validation     loss : 0.34089608983693365 AUC : 0.8011477142572403\n",
      "Epoch : 239 Train      loss : 0.4175866742591506 AUC : 0.7925602277119955\n",
      "Validation     loss : 0.3421677749737545 AUC : 0.8067554533481598\n",
      "Epoch : 240 Train      loss : 0.418611387005644 AUC : 0.7931977987289429\n",
      "Validation     loss : 0.3415544130508131 AUC : 0.7993091493844986\n",
      "Epoch : 241 Train      loss : 0.4192789116378543 AUC : 0.7905345400174459\n",
      "Validation     loss : 0.34122287201715984 AUC : 0.8075886964797974\n",
      "Epoch : 242 Train      loss : 0.41856682286548647 AUC : 0.7916406432787577\n",
      "Validation     loss : 0.34148268234540513 AUC : 0.8005499988794327\n",
      "Epoch : 243 Train      loss : 0.41864378124761725 AUC : 0.7922046581904092\n",
      "Validation     loss : 0.34169297101016305 AUC : 0.8078906536102295\n",
      "Epoch : 244 Train      loss : 0.4179877212748701 AUC : 0.7927324891090393\n",
      "Validation     loss : 0.3402758219798025 AUC : 0.8035383075475693\n",
      "Epoch : 245 Train      loss : 0.41696766039096184 AUC : 0.7934800148010253\n",
      "Validation     loss : 0.3430662141989786 AUC : 0.810623899102211\n",
      "---------------------saved--------------------\n",
      "Epoch : 246 Train      loss : 0.4189367333404959 AUC : 0.793876854578654\n",
      "Validation     loss : 0.3412761981407908 AUC : 0.8038665950298309\n",
      "Epoch : 247 Train      loss : 0.4193524434867001 AUC : 0.7898751338322958\n",
      "Validation     loss : 0.3412798980149489 AUC : 0.8025955855846405\n",
      "Epoch : 248 Train      loss : 0.4186510759441253 AUC : 0.7943854173024495\n",
      "Validation     loss : 0.34060359305281945 AUC : 0.8018965423107147\n",
      "Epoch : 249 Train      loss : 0.41798498182495264 AUC : 0.7928463141123453\n",
      "Validation     loss : 0.3402977584884278 AUC : 0.8042194545269012\n",
      "Epoch : 250 Train      loss : 0.4169624313251488 AUC : 0.7930830836296081\n",
      "Validation     loss : 0.34020458366526574 AUC : 0.8082622289657593\n",
      "Epoch : 251 Train      loss : 0.4169281754757696 AUC : 0.7935859998067222\n",
      "Validation     loss : 0.3410794751758243 AUC : 0.806010976433754\n",
      "Epoch : 252 Train      loss : 0.4188236588893504 AUC : 0.790589972337087\n",
      "Validation     loss : 0.34140692009389945 AUC : 0.8024464994668961\n",
      "Epoch : 253 Train      loss : 0.4196536309056809 AUC : 0.7930218418439229\n",
      "Validation     loss : 0.3418032975378508 AUC : 0.8028800338506699\n",
      "Epoch : 254 Train      loss : 0.4186637636675225 AUC : 0.791843855381012\n",
      "Validation     loss : 0.3411572467506906 AUC : 0.8073253184556961\n",
      "Epoch : 255 Train      loss : 0.4181211050809098 AUC : 0.7944235682487487\n",
      "Validation     loss : 0.34089963043559224 AUC : 0.8025036603212357\n",
      "Epoch : 256 Train      loss : 0.41755517436336775 AUC : 0.7928294936815895\n",
      "Validation     loss : 0.3403925689358393 AUC : 0.8059455752372742\n",
      "Epoch : 257 Train      loss : 0.41649680082266227 AUC : 0.7935173670450847\n",
      "Validation     loss : 0.3405230254417638 AUC : 0.8020779639482498\n",
      "Epoch : 258 Train      loss : 0.4166182555280775 AUC : 0.7919614950815838\n",
      "Validation     loss : 0.34191957214666757 AUC : 0.8087147176265717\n",
      "Epoch : 259 Train      loss : 0.41702858828590395 AUC : 0.7936446507771809\n",
      "Validation     loss : 0.3404804495875734 AUC : 0.8008095175027847\n",
      "Epoch : 260 Train      loss : 0.41618557390201977 AUC : 0.7934954841931661\n",
      "Validation     loss : 0.34031012422817836 AUC : 0.8050220906734467\n",
      "Epoch : 261 Train      loss : 0.4157633028495972 AUC : 0.7928043206532797\n",
      "Validation     loss : 0.34091964909441275 AUC : 0.8068459779024124\n",
      "Epoch : 262 Train      loss : 0.41547943882737354 AUC : 0.7939124941825866\n",
      "Validation     loss : 0.3413177989040878 AUC : 0.8004755079746246\n",
      "Epoch : 263 Train      loss : 0.41713187745676195 AUC : 0.7946942051251727\n",
      "Validation     loss : 0.3427053482717471 AUC : 0.796614944934845\n",
      "Epoch : 264 Train      loss : 0.41679827770061517 AUC : 0.7927547852198282\n",
      "Validation     loss : 0.3404139426724001 AUC : 0.8066088110208511\n",
      "Epoch : 265 Train      loss : 0.4160565787426454 AUC : 0.7931860287984214\n",
      "Validation     loss : 0.34032246356769613 AUC : 0.804685041308403\n",
      "Epoch : 266 Train      loss : 0.4153800397193673 AUC : 0.794824794928233\n",
      "Validation     loss : 0.34088517962472314 AUC : 0.804894357919693\n",
      "Epoch : 267 Train      loss : 0.41536366398041497 AUC : 0.7941200772921244\n",
      "Validation     loss : 0.340610122000063 AUC : 0.803750291466713\n",
      "Epoch : 268 Train      loss : 0.4156488218014678 AUC : 0.7945204496383668\n",
      "Validation     loss : 0.3400379747709207 AUC : 0.8075891137123108\n",
      "Epoch : 269 Train      loss : 0.41564257856356 AUC : 0.793432633082072\n",
      "Validation     loss : 0.33972854832648886 AUC : 0.8071407377719879\n",
      "Epoch : 270 Train      loss : 0.41526312029422396 AUC : 0.7941223382949829\n",
      "Validation     loss : 0.3409025721307646 AUC : 0.8060457706451416\n",
      "Epoch : 271 Train      loss : 0.4162501806539972 AUC : 0.7924964825312296\n",
      "Validation     loss : 0.3403000854576611 AUC : 0.8041217774152756\n",
      "Epoch : 272 Train      loss : 0.4163863867745813 AUC : 0.7947177052497865\n",
      "Validation     loss : 0.34056788100048996 AUC : 0.8030188530683517\n",
      "Epoch : 273 Train      loss : 0.41605136799209586 AUC : 0.7914337396621705\n",
      "Validation     loss : 0.33890781896877775 AUC : 0.808409571647644\n",
      "Epoch : 274 Train      loss : 0.41579472754529445 AUC : 0.7938568393389386\n",
      "Validation     loss : 0.3403284635307521 AUC : 0.8003498315811157\n",
      "Epoch : 275 Train      loss : 0.41630916480240937 AUC : 0.7933874805768331\n",
      "Validation     loss : 0.34236972615465494 AUC : 0.805796205997467\n",
      "Epoch : 276 Train      loss : 0.41660405310790066 AUC : 0.7949813922246298\n",
      "Validation     loss : 0.34062314222426426 AUC : 0.8051658272743225\n",
      "Epoch : 277 Train      loss : 0.41556935245651555 AUC : 0.7923598249753316\n",
      "Validation     loss : 0.3414274881153273 AUC : 0.807148277759552\n",
      "Epoch : 278 Train      loss : 0.4161266246404063 AUC : 0.7948362429936727\n",
      "Validation     loss : 0.34132228749138166 AUC : 0.8085779845714569\n",
      "Epoch : 279 Train      loss : 0.41518146564169583 AUC : 0.7939862449963887\n",
      "Validation     loss : 0.3410935740324283 AUC : 0.8026630133390427\n",
      "Epoch : 280 Train      loss : 0.4144325089283226 AUC : 0.793563715616862\n",
      "Validation     loss : 0.34036371908473834 AUC : 0.8039378374814987\n",
      "Epoch : 281 Train      loss : 0.4139542088369221 AUC : 0.793818481763204\n",
      "Validation     loss : 0.3413887789175608 AUC : 0.8100656569004059\n",
      "Epoch : 282 Train      loss : 0.4154466906309103 AUC : 0.7951537609100341\n",
      "Validation     loss : 0.3402644909975743 AUC : 0.8045099526643753\n",
      "Epoch : 283 Train      loss : 0.4137267460597892 AUC : 0.7947475671768188\n",
      "Validation     loss : 0.34095556703378616 AUC : 0.8060501962900162\n",
      "Epoch : 284 Train      loss : 0.4138898422429078 AUC : 0.7946406364440917\n",
      "Validation     loss : 0.34090325566400886 AUC : 0.8021024316549301\n",
      "Epoch : 285 Train      loss : 0.41400379211754423 AUC : 0.7938059210777283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation     loss : 0.3410150758788893 AUC : 0.8105081915855408\n",
      "Epoch : 286 Train      loss : 0.413842964542659 AUC : 0.7954489707946778\n",
      "Validation     loss : 0.3397961749835994 AUC : 0.803643062710762\n",
      "Epoch : 287 Train      loss : 0.4137016197242487 AUC : 0.7940648516019184\n",
      "Validation     loss : 0.34059965012387733 AUC : 0.8097044378519058\n",
      "Epoch : 288 Train      loss : 0.41337139181919075 AUC : 0.7941858212153118\n",
      "Validation     loss : 0.33982443369791715 AUC : 0.8054544627666473\n",
      "Epoch : 289 Train      loss : 0.41331213445814274 AUC : 0.7961366295814515\n",
      "Validation     loss : 0.3400647900904057 AUC : 0.8025496453046799\n",
      "Epoch : 290 Train      loss : 0.41448666467846984 AUC : 0.7947105725606283\n",
      "Validation     loss : 0.3401615845890281 AUC : 0.805616170167923\n",
      "Epoch : 291 Train      loss : 0.41373473659438886 AUC : 0.7945653398831686\n",
      "Validation     loss : 0.3401273190411197 AUC : 0.8029045313596725\n",
      "Epoch : 292 Train      loss : 0.4139274906610142 AUC : 0.7940112551053365\n",
      "Validation     loss : 0.3414228611396823 AUC : 0.8102971315383911\n",
      "Epoch : 293 Train      loss : 0.41404742828856156 AUC : 0.7962491671244302\n",
      "Validation     loss : 0.34001259232065423 AUC : 0.8057315051555634\n",
      "Epoch : 294 Train      loss : 0.41448994287008994 AUC : 0.792785867055257\n",
      "Validation     loss : 0.34065175586826213 AUC : 0.8081769049167633\n",
      "Epoch : 295 Train      loss : 0.41526150850873395 AUC : 0.794457189242045\n",
      "Validation     loss : 0.33978071821222117 AUC : 0.8038876056671143\n",
      "Epoch : 296 Train      loss : 0.41424212420384854 AUC : 0.7950414339701337\n",
      "Validation     loss : 0.3417800882734642 AUC : 0.8060078769922256\n",
      "Epoch : 297 Train      loss : 0.4150297462146806 AUC : 0.7938358187675476\n",
      "Validation     loss : 0.34035152494851006 AUC : 0.8025831133127213\n",
      "Epoch : 298 Train      loss : 0.41498936835273287 AUC : 0.7945153315862019\n",
      "Validation     loss : 0.3403554955865621 AUC : 0.8046200573444366\n",
      "Epoch : 299 Train      loss : 0.41437936843262685 AUC : 0.7952630201975505\n",
      "Validation     loss : 0.34166895786051055 AUC : 0.8111095279455185\n",
      "---------------------saved--------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "epoch_num = 300\n",
    "initial_lr = 0.1\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "initial_learning_rate=initial_lr, decay_steps=3000, decay_rate=0.96, staircase=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=20.0, epsilon=0.1)\n",
    "\n",
    "loss_train_list = []\n",
    "auc_train_list = []\n",
    "loss_val_list = []\n",
    "auc_val_list = []\n",
    "max_auc = 0.8\n",
    "best_epoch = 0\n",
    "for epoch in range(epoch_num):\n",
    "    loss_train = 0\n",
    "    auc_train = 0\n",
    "    train_q_batches, train_a_batches = shuffle_list(train_q_batches, train_a_batches)\n",
    "    for q,a in zip(train_q_batches, train_a_batches):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logit = layer.call(q,a, training=True)\n",
    "            \n",
    "            loss_batch, auc_batch = loss_acc(logit, q,a)\n",
    "        grad = tape.gradient(loss_batch, layer.trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grad, layer.trainable_variables))\n",
    "        \n",
    "        loss_train += loss_batch.numpy()/len(train_q_batches)\n",
    "       \n",
    "        auc_train += auc_batch.numpy()/len(train_q_batches)\n",
    "        \n",
    "    \n",
    "    print(\"Epoch :\", epoch, \"Train      loss :\",loss_train, \"AUC :\", auc_train)\n",
    "    loss_train_list.append(loss_train)\n",
    "    auc_train_list.append(auc_train)\n",
    "    \n",
    "    loss_val = 0\n",
    "    auc_val = 0\n",
    "    for q_val, a_val in zip(val_q_batches, val_a_batches):\n",
    "        logit_val = layer.call(q_val, a_val)\n",
    "        loss_batch_val, auc_batch_val = loss_acc(logit_val, q_val, a_val)\n",
    "        loss_val += loss_batch_val.numpy()/len(val_q_batches)\n",
    "        auc_val += auc_batch_val.numpy()/len(val_q_batches)\n",
    "        \n",
    "    \n",
    "    print(\"Validation     loss :\", loss_val, \"AUC :\", auc_val)\n",
    "    loss_val_list.append(loss_val)\n",
    "    auc_val_list.append(auc_val)\n",
    "    if auc_val > max_auc:\n",
    "        max_auc = auc_val\n",
    "        best_epoch = epoch\n",
    "        root = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                           model=layer)\n",
    "        checkpoint_dir = './ckpt_'+ str(auc_val*1000)[:3] + \"_\" + str(epoch)\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "        root.save(checkpoint_prefix)\n",
    "        print(\"---------------------saved--------------------\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:15:46.578907Z",
     "start_time": "2020-12-25T19:15:46.480885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_train_list, label='train loss')\n",
    "plt.plot(loss_val_list, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:15:49.224897Z",
     "start_time": "2020-12-25T19:15:49.136877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX VAL AUC : 0.8111095279455185 epoch :  299\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"MAX VAL AUC :\", max(auc_val_list), \"epoch : \", auc_val_list.index(max(auc_val_list)))\n",
    "plt.plot(auc_train_list, label='train auc')\n",
    "plt.plot(auc_val_list, label='validation auc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:15:54.395845Z",
     "start_time": "2020-12-25T19:15:53.714661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test     loss : 0.34348594686851974 AUC : 0.8217064380645751\n"
     ]
    }
   ],
   "source": [
    "loss_test = 0\n",
    "auc_test = 0\n",
    "root.restore(tf.train.latest_checkpoint('./ckpt_811_299'))\n",
    "for i in range(len(test_q_batches)):\n",
    "    test_q_batches[i], test_a_batches[i] = shuffle_list(test_q_batches[i], test_a_batches[i], tolist=False)\n",
    "\n",
    "for q_test, a_test in zip(test_q_batches, test_a_batches):\n",
    "    logit_test = layer.call(q_test, a_test)\n",
    "    loss_batch_test, auc_batch_test = loss_acc(logit_test, q_test, a_test)\n",
    "    loss_test += loss_batch_test.numpy()/len(test_q_batches)\n",
    "    auc_test += auc_batch_test.numpy()/len(test_q_batches)\n",
    "\n",
    "print(\"Test     loss :\", loss_test, \"AUC :\", auc_test)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
